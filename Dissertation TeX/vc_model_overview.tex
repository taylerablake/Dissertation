\chapter{Grouped regularization via the Non-negative Garrote}
\label{groupedRegNNGarrote.ch}

\section{Estimation in functional varying-coefficient models}

The classical linear model expresses the influence of covariates $X_1, X_2, \dots, X_p$ on the response variable $Y$ via 

\begin{equation}
Y = \beta_0 + beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p \label{classical_linear_model}
\end{equation}

Blah blah blah, motivate extending classical linear models to VC models by elaborating the demands of longitudinal data encountered in natural and life sciences, biomedicine, and other social and life sciences, particularly clinical trials, like the AIDS cohort CD4 data. Varying coefficient models extend \eqref{classical_linear_model}, allowing the effect of covariates as specified by model parameters to change with the value of the covariates themselves.  

Zeger and Diggle (1994) consider the partially linear model 




Hoover, RIce, Wu and Yang (1998) considered the following model:

\begin{equation}
Y\left(t\right) =  \bfX^T\left(t\right)\bfbeta \left(t\right) + \epsilon\left(t\right) \label{hoover_rice_wu_VC_model}
\end{equation}

They propose smoothing splines and local polynomials for estimating the coefficient functions, $\bfbeta\left(t\right) = \left( \beta_0\left(t\right), \beta_1\left(t\right),\dots,\beta_p\left(t\right) \right)^T$. 

Hastie and Tibshirani generalize this concept to the case that each of the coefficient functions may depend on different influencer variables. They assume that we observe predictors $\boldmath{R} = \left(R_1, R_2, \dots, R_p\right)^T$ in addition to $X_1, X_2, \dots, X_p$, and suppose that the distribution of the response $Y$ depends on some parameter $\eta$. Hastie and Tibshirani  varying-coefficient model has the form

\begin{equation}
\eta = \beta_0 + \beta_1\left(R_1\right) \label{hastie_tibshiran_VC_model}
\end{equation}


